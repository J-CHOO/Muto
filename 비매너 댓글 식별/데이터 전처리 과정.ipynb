{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68696f7d-99f7-4a1b-97b1-882d0c5565e9",
   "metadata": {},
   "source": [
    "# [모의 캐글 - 게임] 비매너 댓글 식별 \n",
    "\n",
    "- 자연어 multi label classification 과제\n",
    "- 작성자 : MNC Sukyung Kim (skkim@mnc.ai)\n",
    "\n",
    "참고 논문 : \n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa42a1-848b-4d3b-b13e-b65cf0972404",
   "metadata": {},
   "source": [
    "# 1. 환경 설정 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c0e90b-6f4c-45fd-b83c-140dcde11d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting fastprogress\n",
      "  Downloading fastprogress-1.0.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (3.5.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets\n",
      "  Downloading ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.8/121.8 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from attrdict->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (2020.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (1.22.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.29.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (8.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
      "Collecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 6)) (4.51.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 6)) (2.24.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.1.18-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.6/764.6 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 6)) (5.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 6)) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.0.5)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.1.3)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (6.4.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (7.28.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers->-r requirements.txt (line 6)) (3.7.4.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (7.0.6)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (2.7.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (50.3.1.post20201107)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (4.8.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (6.4.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 6)) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 6)) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 6)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->-r requirements.txt (line 6)) (2020.12.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers->-r requirements.txt (line 6)) (8.0.3)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (21.2.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (6.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (2.11.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (21.1.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (1.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.5.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (2.20)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->-r requirements.txt (line 7)) (0.5.1)\n",
      "Installing collected packages: tokenizers, regex, sacremoses, jupyterlab-widgets, fastprogress, attrdict, huggingface-hub, transformers, widgetsnbextension, ipywidgets\n",
      "Successfully installed attrdict-2.0.1 fastprogress-1.0.2 huggingface-hub-0.4.0 ipywidgets-7.6.5 jupyterlab-widgets-1.0.2 regex-2022.1.18 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2 widgetsnbextension-3.5.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff15bef2-c669-4cb1-bf76-256154c4858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 16:04:24.968852: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-23 16:04:25.941033: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-02-23 16:04:25.969893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2022-02-23 16:04:25.969946: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-02-23 16:04:25.972775: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-02-23 16:04:25.972842: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-02-23 16:04:25.974068: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-02-23 16:04:25.974328: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-02-23 16:04:25.974429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-02-23 16:04:25.975031: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-02-23 16:04:25.975188: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-02-23 16:04:25.975204: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-23 16:04:25.975714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-23 16:04:25.989638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-02-23 16:04:25.989659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import *\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "from transformers import logging, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from transformers import ( \n",
    "    BertConfig,\n",
    "    ElectraConfig,\n",
    "    ElectraConfig\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,  \n",
    "    AutoTokenizer,\n",
    "    ElectraTokenizer,\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    AutoModel, \n",
    "    ElectraForSequenceClassification,\n",
    "    BertForSequenceClassification\n",
    ")\n",
    "from hanspell import spell_checker\n",
    "from pykospacing import Spacing\n",
    "from soynlp.normalizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c95b317-b37f-4c59-8eaf-25ce048eb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs:  1\n",
      "Does GPU exist? :  True\n"
     ]
    }
   ],
   "source": [
    "# 사용할 GPU 지정\n",
    "print(\"number of GPUs: \", torch.cuda.device_count())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Does GPU exist? : \", use_cuda)\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ffbcad1-d170-462f-807d-41760e65f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True 일 때 코드를 실행하면 example 등을 보여줌\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7484847-924d-4f99-8b41-190ae4f192e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file loaded.\n",
      "beomi/kcbert-base\n"
     ]
    }
   ],
   "source": [
    "# config 파일 불러오기\n",
    "config_path = os.path.join('config.json')\n",
    "\n",
    "def set_config(config_path):\n",
    "    if os.path.lexists(config_path):\n",
    "        with open(config_path) as f:\n",
    "            args = AttrDict(json.load(f))\n",
    "            print(\"config file loaded.\")\n",
    "            print(args.pretrained_model)\n",
    "    else:\n",
    "        assert False, 'config json file cannot be found.. please check the path again.'\n",
    "    \n",
    "    return args\n",
    "    \n",
    "\n",
    "# 코드 중간중간에 끼워넣어 리셋 가능\n",
    "args = set_config(config_path)\n",
    "\n",
    "# 결과 저장 폴더 미리 생성\n",
    "os.makedirs(args.result_dir, exist_ok=True)\n",
    "os.makedirs(args.config_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04c99c-208b-46a1-82cd-a7c9c776c8ad",
   "metadata": {},
   "source": [
    "# 2. EDA 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87df6631-40e2-4c33-bacc-6548f9459d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "# data 경로 설정  \n",
    "train_path = os.path.join(args.data_dir,'/USER/team_project3/data/train.csv')\n",
    "\n",
    "print(\"train 데이터 경로가 올바른가요? : \", os.path.lexists(train_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3123598-d707-467a-a380-99644a9a3637",
   "metadata": {},
   "source": [
    "### 2-1. Train 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d5cb19-0e61-4358-9a9b-c690cbe8c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate  \n",
       "3                                           일본 축구 져라    none  none  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path, encoding = 'UTF-8-SIG')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10dee23-db6d-4fce-8b06-054c3457adaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecb32ed-e7f9-4640-89c2-87005a9aed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias classes:  ['none' 'others' 'gender']\n",
      "hate classes:  ['none' 'hate']\n"
     ]
    }
   ],
   "source": [
    "print(\"bias classes: \", train_df.bias.unique())\n",
    "print(\"hate classes: \", train_df.hate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faecbd1a-82ee-40ed-b81a-2984674b669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>none</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1216</td>\n",
       "      <td>83</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>2068</td>\n",
       "      <td>3422</td>\n",
       "      <td>5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>1437</td>\n",
       "      <td>141</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4721</td>\n",
       "      <td>3646</td>\n",
       "      <td>8367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hate    hate  none   All\n",
       "bias                    \n",
       "gender  1216    83  1299\n",
       "none    2068  3422  5490\n",
       "others  1437   141  1578\n",
       "All     4721  3646  8367"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_df.bias, train_df.hate, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3802b-a501-4adc-9f9a-6968df7684d3",
   "metadata": {},
   "source": [
    "### 2-2. Test 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86211318-bfaa-47c7-9653-63a13905dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(args.data_dir,'/USER/team_project3/data/test.csv')\n",
    "print(\"test 데이터 경로가 올바른가요? : \", os.path.lexists(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a713f829-09c9-468a-8266-4bd555e29906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]</td>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]</td>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]</td>\n",
       "      <td>누군데 얘네?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"</td>\n",
       "      <td>쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]</td>\n",
       "      <td>안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title  \\\n",
       "0   0        류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]   \n",
       "1   1  \"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]   \n",
       "2   2     입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]   \n",
       "3   3        아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"   \n",
       "4   4         구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]   \n",
       "\n",
       "                                             comment  \n",
       "0                                      둘다 넘 좋다~행복하세요  \n",
       "1               근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데  \n",
       "2                                            누군데 얘네?  \n",
       "3  쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...  \n",
       "4  안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad5fbb7-acb5-47cb-b0f3-b220bf78ab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb5aa8-6284-4066-a69d-a1539c5287a5",
   "metadata": {},
   "source": [
    "### 2-3. 데이터 전처리 (Label Encoding)\n",
    "bias, hate 라벨들의 class를 정수로 변경하여 라벨 인코딩을 하기 위한 딕셔너리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11018420-84da-40ac-b892-4e47f20dd83f",
   "metadata": {},
   "source": [
    "- bias, hate 컬럼을 합쳐서 하나의 라벨로 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c61bc4-da4a-4fc3-9cff-62079051ed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['none' 'none']\n",
      " ['none' 'hate']\n",
      " ['others' 'none']\n",
      " ['others' 'hate']\n",
      " ['gender' 'none']\n",
      " ['gender' 'hate']]\n"
     ]
    }
   ],
   "source": [
    "# 두 라벨의 가능한 모든 조합 만들기\n",
    "combinations = np.array(np.meshgrid(train_df.bias.unique(), train_df.hate.unique())).T.reshape(-1,2)\n",
    "\n",
    "if DEBUG==True:\n",
    "    print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1f00cb-8009-460f-8903-ca876d647ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['none', 'none'], dtype=object), array(['none', 'hate'], dtype=object), array(['others', 'hate'], dtype=object), array(['none', 'none'], dtype=object), array(['none', 'none'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# bias, hate 컬럼을 합친 것\n",
    "bias_hate = list(np.array([train_df['bias'].values, train_df['hate'].values]).T.reshape(-1,2))\n",
    "\n",
    "if DEBUG==True:\n",
    "    print(bias_hate[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26376de0-2a54-44c2-a8af-f20025b9798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  label  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none      0  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate      1  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate      3  \n",
       "3                                           일본 축구 져라    none  none      0  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, arr in enumerate(bias_hate):\n",
    "    for idx, elem in enumerate(combinations):\n",
    "        if np.array_equal(elem, arr):\n",
    "            labels.append(idx)\n",
    "\n",
    "train_df['label'] = labels\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0c2821e-0687-4d5f-b63c-fba71d03c508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"title\"] = train_df[\"title\"].str.replace(pat=r'[^\\w]', repl=r'', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9e47413-c803-4f57-a8b9-40b68cae1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"comment\"] = train_df[\"comment\"].str.replace(pat=r'[^\\w]', repl=r'', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b964a3-35cc-4e68-a6d0-70a50fedb6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터션샤인변요한김태리와같은양복입고학당방문이유는</td>\n",
       "      <td>김태리정말연기잘해진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC현장극사실주의현실가장보통의연애김래원X공효진16년만의랑데부종합</td>\n",
       "      <td>공효진발연기나이질생각이읍던데왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재리듬체조학원선생님하고싶은일해서행복하다</td>\n",
       "      <td>누구처럼돈만밝히는저급인생은살아가지마시길행복은머니순이아니니깐작은거에감사하고항상좋은일만...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV김해숙허스토리촬영후우울증얻었다</td>\n",
       "      <td>일본축구져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>단독임현주아나운서노브라챌린지방송덕에낸용기자연스런논의의창됐으면인터뷰</td>\n",
       "      <td>난절대로임현주욕하는인간이랑은안논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>배우이필립SNS스타연인에게초호화프러포즈눈길</td>\n",
       "      <td>아니근데튜닝한사람은프러포즈받지도결혼도못함ㅋㅋㅋ지들은돈없어서못하는것들이ㅋㅋㅋㅋ아이고배...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>SC이슈마약백스텝김새롬탓실형피한이찬오이미지는치명상종합</td>\n",
       "      <td>그러니깐여자를잘만나야되징글징글한것들만나면인생끝가지돌아가게되는듯근데왜다들김새롬편을들어...</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>POP이슈그들만의세상홍상수김민희새해데이트에반응싸늘</td>\n",
       "      <td>참으로아름다운커플입니다늘행복하시고새해에도늘꽃길만걸으시길축원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>종합시크릿마더김소연누가죽였나송윤아와갈등</td>\n",
       "      <td>재미가없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>허지웅소속사악성림프종진단치료전념공식</td>\n",
       "      <td>쭉쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  \\\n",
       "0               미스터션샤인변요한김태리와같은양복입고학당방문이유는   \n",
       "1      SC현장극사실주의현실가장보통의연애김래원X공효진16년만의랑데부종합   \n",
       "2                  손연재리듬체조학원선생님하고싶은일해서행복하다   \n",
       "3                     섹션TV김해숙허스토리촬영후우울증얻었다   \n",
       "4     단독임현주아나운서노브라챌린지방송덕에낸용기자연스런논의의창됐으면인터뷰   \n",
       "...                                    ...   \n",
       "8362               배우이필립SNS스타연인에게초호화프러포즈눈길   \n",
       "8363         SC이슈마약백스텝김새롬탓실형피한이찬오이미지는치명상종합   \n",
       "8364           POP이슈그들만의세상홍상수김민희새해데이트에반응싸늘   \n",
       "8365                 종합시크릿마더김소연누가죽였나송윤아와갈등   \n",
       "8366                   허지웅소속사악성림프종진단치료전념공식   \n",
       "\n",
       "                                                comment    bias  hate  label  \n",
       "0                                           김태리정말연기잘해진짜    none  none      0  \n",
       "1                                공효진발연기나이질생각이읍던데왜계속주연일까    none  hate      1  \n",
       "2     누구처럼돈만밝히는저급인생은살아가지마시길행복은머니순이아니니깐작은거에감사하고항상좋은일만...  others  hate      3  \n",
       "3                                                일본축구져라    none  none      0  \n",
       "4                                    난절대로임현주욕하는인간이랑은안논다    none  none      0  \n",
       "...                                                 ...     ...   ...    ...  \n",
       "8362  아니근데튜닝한사람은프러포즈받지도결혼도못함ㅋㅋㅋ지들은돈없어서못하는것들이ㅋㅋㅋㅋ아이고배...  others  hate      3  \n",
       "8363  그러니깐여자를잘만나야되징글징글한것들만나면인생끝가지돌아가게되는듯근데왜다들김새롬편을들어...  gender  hate      5  \n",
       "8364                참으로아름다운커플입니다늘행복하시고새해에도늘꽃길만걸으시길축원합니다    none  none      0  \n",
       "8365                                             재미가없어요    none  none      0  \n",
       "8366                                               쭉쉬세요    none  hate      1  \n",
       "\n",
       "[8367 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ca45be-bb10-4290-8c66-db72f96be6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Spacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d4e1bb1-d241-47d8-a5a8-39c6af2ca0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번쨰 진행중...\n",
      "500번쨰 진행중...\n",
      "1000번쨰 진행중...\n",
      "1500번쨰 진행중...\n",
      "2000번쨰 진행중...\n",
      "2500번쨰 진행중...\n",
      "3000번쨰 진행중...\n",
      "3500번쨰 진행중...\n",
      "4000번쨰 진행중...\n",
      "4500번쨰 진행중...\n",
      "5000번쨰 진행중...\n",
      "5500번쨰 진행중...\n",
      "6000번쨰 진행중...\n",
      "6500번쨰 진행중...\n",
      "7000번쨰 진행중...\n",
      "7500번쨰 진행중...\n",
      "8000번쨰 진행중...\n"
     ]
    }
   ],
   "source": [
    "title_list = []\n",
    "for i, title in enumerate(train_df[\"title\"]):\n",
    "        title_list.append(spacing(title))\n",
    "        if i % 500 == 0:\n",
    "            print(f\"{i}번쨰 진행중...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ae4735a-aa33-4124-b50c-86a8354970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"title\"] = title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1fd95ac-d1b9-43bf-b0a4-8b4d88bf151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번쨰 진행중...\n",
      "500번쨰 진행중...\n",
      "1000번쨰 진행중...\n",
      "1500번쨰 진행중...\n",
      "2000번쨰 진행중...\n",
      "2500번쨰 진행중...\n",
      "3000번쨰 진행중...\n",
      "3500번쨰 진행중...\n",
      "4000번쨰 진행중...\n",
      "4500번쨰 진행중...\n",
      "5000번쨰 진행중...\n",
      "5500번쨰 진행중...\n",
      "6000번쨰 진행중...\n",
      "6500번쨰 진행중...\n",
      "7000번쨰 진행중...\n",
      "7500번쨰 진행중...\n",
      "8000번쨰 진행중...\n"
     ]
    }
   ],
   "source": [
    "comment_list = []\n",
    "for i, comment in enumerate(train_df[\"comment\"]):\n",
    "        comment_list.append(spacing(comment))\n",
    "        if i % 500 == 0:\n",
    "            print(f\"{i}번쨰 진행중...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa0a89a9-1bbc-40b1-8806-8570d2c6c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"comment\"] = comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b167355-c6ac-4d5c-9191-35ffcf71e4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터션 샤인변 요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC 현장 극사실주의 현실 가장 보통의 연애 김래원 X공효진 16년 만의 랑데부종합</td>\n",
       "      <td>공효진발 연기나 이질 생각이 읍던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님하고 싶은 일해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션 TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창됐으면 인터뷰</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길</td>\n",
       "      <td>아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ㅋㅋㅋ지들은 돈 없어서 못하는...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>SC 이슈 마약백스텝 김새롬 탓 실형 피한 이찬오 이미지는 치명상종합</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 되징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯 ...</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>POP 이슈 그들만의 세상 홍상수 김민희 새해 데이트에 반응 싸늘</td>\n",
       "      <td>참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>종합시크릿마더 김소연 누가 죽였나 송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>허지웅 소속 사 악성 림프종 진단치료 전념 공식</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                  미스터션 샤인변 요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1       SC 현장 극사실주의 현실 가장 보통의 연애 김래원 X공효진 16년 만의 랑데부종합   \n",
       "2                        손연재 리듬체조 학원 선생님하고 싶은 일해서 행복하다   \n",
       "3                          섹션 TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4     단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창됐으면 인터뷰   \n",
       "...                                                ...   \n",
       "8362                    배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길   \n",
       "8363            SC 이슈 마약백스텝 김새롬 탓 실형 피한 이찬오 이미지는 치명상종합   \n",
       "8364              POP 이슈 그들만의 세상 홍상수 김민희 새해 데이트에 반응 싸늘   \n",
       "8365                        종합시크릿마더 김소연 누가 죽였나 송윤아와 갈등   \n",
       "8366                        허지웅 소속 사 악성 림프종 진단치료 전념 공식   \n",
       "\n",
       "                                                comment    bias  hate  label  \n",
       "0                                        김태리 정말 연기 잘해진짜    none  none      0  \n",
       "1                         공효진발 연기나 이질 생각이 읍던데 왜 계속 주연일까    none  hate      1  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate      3  \n",
       "3                                              일본 축구 져라    none  none      0  \n",
       "4                              난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none      0  \n",
       "...                                                 ...     ...   ...    ...  \n",
       "8362  아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ㅋㅋㅋ지들은 돈 없어서 못하는...  others  hate      3  \n",
       "8363  그러니깐 여자를 잘 만나야 되징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯 ...  gender  hate      5  \n",
       "8364       참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다    none  none      0  \n",
       "8365                                            재미가 없어요    none  none      0  \n",
       "8366                                              쭉 쉬세요    none  hate      1  \n",
       "\n",
       "[8367 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "285e7a7d-2b67-4890-aa26-b1cdb573f5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번쨰 진행중...\n",
      "500번쨰 진행중...\n",
      "1000번쨰 진행중...\n",
      "1500번쨰 진행중...\n",
      "2000번쨰 진행중...\n",
      "2500번쨰 진행중...\n",
      "3000번쨰 진행중...\n",
      "3500번쨰 진행중...\n",
      "4000번쨰 진행중...\n",
      "4500번쨰 진행중...\n",
      "5000번쨰 진행중...\n",
      "5500번쨰 진행중...\n",
      "6000번쨰 진행중...\n",
      "6500번쨰 진행중...\n",
      "7000번쨰 진행중...\n",
      "7500번쨰 진행중...\n",
      "8000번쨰 진행중...\n"
     ]
    }
   ],
   "source": [
    "spell_comment_list = []\n",
    "for i, title in enumerate(train_df[\"title\"]):\n",
    "        spelled_title = spell_checker.check(title)\n",
    "        hanspell_title = spelled_title.checked\n",
    "        spell_title_list.append(hanspell_title)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"{i}번쨰 진행중...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95e10760-6818-4f64-b78c-f6b9286ac13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"title\"] = spell_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e513d7f-d5a2-40cd-ab86-a61781ce5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번쨰 진행중...\n",
      "500번쨰 진행중...\n",
      "1000번쨰 진행중...\n",
      "1500번쨰 진행중...\n",
      "2000번쨰 진행중...\n",
      "2500번쨰 진행중...\n",
      "3000번쨰 진행중...\n",
      "3500번쨰 진행중...\n",
      "4000번쨰 진행중...\n",
      "4500번쨰 진행중...\n",
      "5000번쨰 진행중...\n",
      "5500번쨰 진행중...\n",
      "6000번쨰 진행중...\n",
      "6500번쨰 진행중...\n",
      "7000번쨰 진행중...\n",
      "7500번쨰 진행중...\n",
      "8000번쨰 진행중...\n"
     ]
    }
   ],
   "source": [
    "spell_comment_list = []\n",
    "for i, comment in enumerate(train_df[\"comment\"]):\n",
    "        spelled_comment = spell_checker.check(comment)\n",
    "        hanspell_comment = spelled_comment.checked\n",
    "        spell_comment_list.append(hanspell_comment)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"{i}번쨰 진행중...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b02842fe-5c51-4357-b4fc-11c342a3e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"comment\"] = spell_comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4bd23c00-56d3-4a67-aa8a-bff1ab8170b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션 샤인 변 요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC 현장 극사실주의 현실 가장 보통의 연애 김래원 X 공효진 16년 만의 랑데부 종합</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션 TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스러운 논의의 창 됐으면...</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길</td>\n",
       "      <td>아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 못...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>SC 이슈 마약 백스텝 김새롬 탓 실형 피한 이찬오 이미지는 치명상 종합</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>POP 이슈 그들만의 세상 홍상수 김민희 새해 데이트에 반응 싸늘</td>\n",
       "      <td>참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>종합 시크릿 마더 김소연 누가 죽였나 송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>허지웅 소속 사 악성 림프종 진단치료 전념 공식</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                 미스터 션 샤인 변 요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1      SC 현장 극사실주의 현실 가장 보통의 연애 김래원 X 공효진 16년 만의 랑데부 종합   \n",
       "2                       손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                           섹션 TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4     단독 임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스러운 논의의 창 됐으면...   \n",
       "...                                                 ...   \n",
       "8362                     배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길   \n",
       "8363           SC 이슈 마약 백스텝 김새롬 탓 실형 피한 이찬오 이미지는 치명상 종합   \n",
       "8364               POP 이슈 그들만의 세상 홍상수 김민희 새해 데이트에 반응 싸늘   \n",
       "8365                       종합 시크릿 마더 김소연 누가 죽였나 송윤아와 갈등   \n",
       "8366                         허지웅 소속 사 악성 림프종 진단치료 전념 공식   \n",
       "\n",
       "                                                comment    bias  hate  label  \n",
       "0                                       김태리 정말 연기 잘해 진짜    none  none      0  \n",
       "1                        공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까    none  hate      1  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate      3  \n",
       "3                                              일본 축구 져라    none  none      0  \n",
       "4                              난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none      0  \n",
       "...                                                 ...     ...   ...    ...  \n",
       "8362  아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 못...  others  hate      3  \n",
       "8363  그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...  gender  hate      5  \n",
       "8364       참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다    none  none      0  \n",
       "8365                                            재미가 없어요    none  none      0  \n",
       "8366                                              쭉 쉬세요    none  hate      1  \n",
       "\n",
       "[8367 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e4ce0a45-9f1c-49d2-9c3d-172323252f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번쨰 진행중...\n",
      "500번쨰 진행중...\n",
      "1000번쨰 진행중...\n",
      "1500번쨰 진행중...\n",
      "2000번쨰 진행중...\n",
      "2500번쨰 진행중...\n",
      "3000번쨰 진행중...\n",
      "3500번쨰 진행중...\n",
      "4000번쨰 진행중...\n",
      "4500번쨰 진행중...\n",
      "5000번쨰 진행중...\n",
      "5500번쨰 진행중...\n",
      "6000번쨰 진행중...\n",
      "6500번쨰 진행중...\n",
      "7000번쨰 진행중...\n",
      "7500번쨰 진행중...\n",
      "8000번쨰 진행중...\n"
     ]
    }
   ],
   "source": [
    "repeat_comment_list = []\n",
    "for i, comment in enumerate(train_df[\"comment\"]):\n",
    "        repeat_comment = repeat_normalize(comment, num_repeats=2)\n",
    "        repeat_comment_list.append(repeat_comment)\n",
    "        if i % 500 == 0:\n",
    "            print(f\"{i}번쨰 진행중...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2439e3e9-0950-41be-890a-40aa4d4a94af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ㅋㅋㅋㅋ 아이고 배 아파죽지ᄏ'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"comment\"][8362] #soynlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "148ee6c5-0abd-43da-8d0d-52661285e225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아니 근데 튜닝한 사람은 프러포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ㅋ 아이고 배 아파죽지ᄏ'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_normalize(train_df[\"comment\"][8362], num_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3878d922-66a0-45dc-b740-eb4482f2bf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'와하하'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_normalize(\"와하하하하하하하하하하\", num_repeats=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0af0c9f4-8be0-4232-b3d5-49ca9cfaa537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train(전처리).csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add80824-55c5-4ca3-9858-5aeee3ede98d",
   "metadata": {},
   "source": [
    "## 3. Dataset 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9956c57-af6a-4330-a531-a338be9da9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3-0. Pre-trained tokenizer 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f2debd1b-9a38-4074-930d-aef2e2b236fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "05da432b-0d40-488c-80e8-492710208421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okt = Okt()\n",
    "# example = \"고기를 아이구 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    "# stop_words = \"이 있 하 것 들 그 되 수 이 보 않 없 나 사람 주 아니 등 같 우리 때 년 가 한 지대하 오 말 일 그렇 위하 때문 그것 두 말하 알 그러나 받 못하 일 그런 또 문제 더 사회 많 그리고 \"\n",
    "\n",
    "# stop_words = set(example.split(' '))\n",
    "# word_tokens = okt.morphs(example)\n",
    "\n",
    "# result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "# print('불용어 제거 전 :',word_tokens) \n",
    "# print('불용어 제거 후 :',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "780cccc5-9fba-40f9-ab5c-dd826113f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = okt.pos(train_df[\"comment\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8931836c-06c9-4414-bf74-c2f7be4487d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"\"\n",
    "for comment in train_df[\"comment\"]:\n",
    "    word_tokens = okt.pos(comment)\n",
    "    \n",
    "    for token in word_tokens:\n",
    "        if token[1] == \"Josa\":\n",
    "            stop_words += (\" \" + token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a1d22941-37e0-4f52-96c9-aa2a01eb11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0133a0f7-20ae-4213-8a25-77e7ba0b33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"\"\n",
    "for word in a:\n",
    "    stop_words += (\" \" + word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2d962200-187c-40e1-894c-ba06ca068fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 겐 고 만 게 럽 인 데 은 대 처 밖 와 의 기 든 에 써 하 깐 단 냐 다 군 예 터 테 래 롭 러 큼 가 즉 구 같 며 차 럼 커 네 엘   스 선 녕 로 도 니 운 치 나 과 론 는 아 곤 저 랑 서 냥 면 께 요 던 여 진 어 을 이 죠 보 지 마 난 를 으 엔 슨 말 들 까 한 야 라 란 조 턴 부\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729076c-ba37-403c-a932-ae2d3b8d53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(example.split(' '))\n",
    "word_tokens = okt.morphs(example)\n",
    "\n",
    "result = [word for word in word_tokens if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd6f75f4-cdf7-4998-8b78-3aa716b7045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.json 에서 지정 이름별로 가져올 라이브러리 지정\n",
    "\n",
    "TOKENIZER_CLASSES = {\n",
    "    \"BertTokenizer\": BertTokenizer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a285fec-0b39-4dce-8dc0-6faa6b027c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Tokenizer 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d0f1e57-caf8-4d67-a2a9-61284a793f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5318926c56b14a47a39fbbb15418a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f398f45b9eb44ed3acc7691122623d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=249928.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2f23268db7486a80a60187e1658bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=619.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PreTrainedTokenizer(name_or_path='beomi/kcbert-base', vocab_size=30000, model_max_len=300, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = TOKENIZER_CLASSES[args.tokenizer_class].from_pretrained(args.pretrained_model)\n",
    "if DEBUG==True:\n",
    "    print(TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "929e31be-1c02-4326-bf72-4e59622c9ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SC 현장 극사실주의 현실 가장 보통의 연애 김래원 X 공효진 16년 만의 랑데부 종합'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['title'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e8cdb8e-41a8-4d51-8aa0-f305782416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 52, 4881, 13623, 392, 10432, 8055, 8454, 8547, 10766, 4042, 13853, 420, 4369, 4165, 57, 314, 4894, 4153, 11678, 4482, 1296, 4042, 1125, 4092, 4131, 18606, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "if DEBUG == True:\n",
    "    example = train_df['title'][1]\n",
    "    print(TOKENIZER(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f174365c-90da-4c32-b6b4-5d66525a0687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 52, 4881, 13623, 392, 10432, 8055, 8454, 8547, 10766, 4042, 13853, 420, 4369, 4165, 57, 314, 4894, 4153, 11678, 4482, 1296, 4042, 1125, 4092, 4131, 18606, 3] \n",
      "\n",
      "['S', '##C', '현장', '극', '##사실', '##주의', '현실', '가장', '보통', '##의', '연애', '김', '##래', '##원', 'X', '공', '##효', '##진', '16', '##년', '만', '##의', '랑', '##데', '##부', '종합'] \n",
      "\n",
      "[52, 4881, 13623, 392, 10432, 8055, 8454, 8547, 10766, 4042, 13853, 420, 4369, 4165, 57, 314, 4894, 4153, 11678, 4482, 1296, 4042, 1125, 4092, 4131, 18606]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG==True:\n",
    "    print(TOKENIZER.encode(example),\"\\n\")\n",
    "    \n",
    "    # 토큰으로 나누기\n",
    "    print(TOKENIZER.tokenize(example),\"\\n\")\n",
    "    \n",
    "    # 토큰 id로 매핑하기\n",
    "    print(TOKENIZER.convert_tokens_to_ids(TOKENIZER.tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1708e-aedb-402f-a9c3-20ebdbe537eb",
   "metadata": {},
   "source": [
    "### 3-1. Dataset 만드는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6f065-671c-435c-8e73-8cad3c1496a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_len, mode = 'train'):\n",
    "\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            try: \n",
    "                self.labels = df['label'].tolist()\n",
    "            except:\n",
    "                assert False, 'CustomDataset Error : \\'label\\' column does not exist in the dataframe'\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "                \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        전체 데이터에서 특정 인덱스 (idx)에 해당하는 기사제목과 댓글 내용을 \n",
    "        토크나이즈한 data('input_ids', 'attention_mask','token_type_ids')의 딕셔너리 형태로 불러옴\n",
    "        \"\"\"\n",
    "        title = self.data.title.iloc[idx]\n",
    "        comment = self.data.comment.iloc[idx]\n",
    "        \n",
    "        tokenized_text = self.tokenizer(title, comment,\n",
    "                             padding= 'max_length',\n",
    "                             max_length=self.max_len,\n",
    "                             truncation=True,\n",
    "                             return_token_type_ids=True,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors = \"pt\")\n",
    "        \n",
    "        data = {'input_ids': tokenized_text['input_ids'].clone().detach().long(),\n",
    "               'attention_mask': tokenized_text['attention_mask'].clone().detach().long(),\n",
    "               'token_type_ids': tokenized_text['token_type_ids'].clone().detach().long(),\n",
    "               }\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            label = self.data.label.iloc[idx]\n",
    "            return data, label\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "\n",
    "    \n",
    "train_dataset = CustomDataset(train_df, TOKENIZER, args.max_seq_len, mode ='train')\n",
    "print(\"train dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27241c-4c3b-498e-9456-871dc3cc2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG ==True :\n",
    "    print(\"dataset sample : \")\n",
    "    print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbadd376-0df2-455c-89f1-9236ba9d32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_plus = tokenizer.encode_plus(\n",
    "#                     sentence,                      # Sentence to encode.\n",
    "#                     add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#                     max_length = 128,           # Pad & truncate all sentences.\n",
    "#                     pad_to_max_length = True,\n",
    "#                     return_attention_mask = True,   # Construct attention masks.\n",
    "#                     return_tensors = 'pt',     # Return pytorch tensors.\n",
    "#                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d12dd-7a1e-423f-8b3d-00bae3c17375",
   "metadata": {},
   "source": [
    "### 3-2. Train, Validation set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb9525-861d-48ba-b495-828b8a08b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=args.seed)\n",
    "\n",
    "train_dataset = CustomDataset(train_data, TOKENIZER, args.max_seq_len, 'train')\n",
    "val_dataset = CustomDataset(val_data, TOKENIZER, args.max_seq_len, 'validation')\n",
    "\n",
    "print(\"Train dataset: \", len(train_dataset))\n",
    "print(\"Validation dataset: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed493727-edd8-43ba-924f-195837306952",
   "metadata": {},
   "source": [
    "## 4. 분류 모델 학습을 위한 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0817a-8b51-4d22-9f31-eb8bd22640cb",
   "metadata": {},
   "source": [
    "### 4-1. BertForSequenceClassification 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a250764-25aa-43e4-a383-f464dc54bc25",
   "metadata": {},
   "source": [
    "\n",
    "(https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)\n",
    "\n",
    "[PretrainedConfig](https://huggingface.co/transformers/v3.0.2/main_classes/configuration.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c0acd-d158-4d36-bfd1-abb47fb618f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# config.json 에 입력된 architecture 에 따라 베이스 모델 설정\n",
    "BASE_MODELS = {\n",
    "    \"BertForSequenceClassification\": BertForSequenceClassification\n",
    "}\n",
    "\n",
    "\n",
    "myModel = BASE_MODELS[args.architecture].from_pretrained(args.pretrained_model, \n",
    "                                                         num_labels = args.num_classes, \n",
    "                                                         output_attentions = False, # Whether the model returns attentions weights.\n",
    "                                                         output_hidden_states = True # Whether the model returns all hidden-states.\n",
    "                                                        )\n",
    "if DEBUG==True:\n",
    "    # 모델 구조 확인\n",
    "    print(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f90f3c-51f6-4b44-a426-a0b36ccfa852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022a093-130f-40ac-b8e5-8decc5c63a6d",
   "metadata": {},
   "source": [
    "### 4-2. 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d37b1b-d491-4d3c-8551-980f78a78337",
   "metadata": {},
   "source": [
    "\n",
    "BertForSequenceClassifier (line 1232부터 참고) [source code](https://github.com/huggingface/transformers/blob/a39dfe4fb122c11be98a563fb8ca43b322e01036/src/transformers/modeling_bert.py#L1284-L1287)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685ce12-7238-4e2a-a20d-11969b568807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myClassifier(nn.Module):\n",
    "    def __init__(self, model, hidden_size = 768, num_classes=args.num_classes, dr_rate=None, params=None):\n",
    "        super(myClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, segment_ids):      \n",
    "        outputs = self.model(input_ids = token_ids, \n",
    "                             token_type_ids = segment_ids.long(), \n",
    "                             attention_mask = attention_mask.float().to(token_ids.device))\n",
    "         \n",
    "        logits = outputs.logits\n",
    "        output = self.softmax(logits)\n",
    "        return output\n",
    "        \n",
    "model = myClassifier(myModel, dr_rate=0.1)\n",
    "\n",
    "# if DEBUG ==True :\n",
    "#     print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99386a8c-7795-454c-9a32-eaf447c6fc4c",
   "metadata": {},
   "source": [
    "### 4-3. 모델 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6bc6f-1df3-46fb-a607-5de3e3cef571",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c441a1-2ce3-46b2-b52d-c0cce7f76873",
   "metadata": {},
   "source": [
    "## 5. 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4643714-c372-463a-8f7e-2955b2d4376a",
   "metadata": {},
   "source": [
    "### 5-0. Early Stopper 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205350d-ce58-42e7-9558-2b405f142ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        msg = ''\n",
    "        # 첫 에폭\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "           \n",
    "        # loss가 줄지 않는다면 -> patience_counter 1 증가\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            # patience 만큼 loss가 줄지 않았다면 학습을 중단합니다.\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "  \n",
    "        # loss가 줄어듬 -> min_loss 갱신, patience_counter 초기화\n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            self.save_model = True\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d11163-6def-448a-9095-19231e9efe64",
   "metadata": {},
   "source": [
    "### 5-1. Epoch 별 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ed2a1-c2e3-43cb-9967-05d85b8546ee",
   "metadata": {},
   "source": [
    "- Adam optimizer의 epsilon 파라미터 eps = 1e-8 는 \"계산 중 0으로 나눔을 방지 하기 위한 아주 작은 숫자 \" 입니다. ([출처](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))\n",
    "- `warmup_ratio` : \n",
    "  - 학습이 진행되면서 학습률을 그 상황에 맞게 가변적으로 적당하게 변경되게 하기 위해 Scheduler를 사용합니다.\n",
    "  - 처음 학습률(Learning rate)를 warm up하기 위한 비율을 설정하는 warmup_ratio을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151484e-978d-4bf3-b7b3-fe2c5ba5eda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = set_config(config_path)\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "# 재현을 위해 모든 곳의 시드 고정\n",
    "seed_val = args.seed\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def train(model, train_data, val_data, args, mode = 'train'):\n",
    "    \n",
    "    # args.run은 실험 이름 (어디까지나 팀원들간의 버전 관리 및 공유 편의를 위한 것으로, 자유롭게 수정 가능합니다.)\n",
    "    print(\"RUN : \", args.run)\n",
    "    shutil.copyfile(\"config.json\", os.path.join(args.config_dir, f\"config_{args.run}.json\"))\n",
    "\n",
    "    early_stopper = LossEarlyStopper(patience=args.patience)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=args.train_batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=args.train_batch_size)\n",
    "\n",
    "    DEBUG=False\n",
    "    \n",
    "    if DEBUG == True:\n",
    "        # 데이터로더가 성공적으로 로드 되었는지 확인\n",
    "        for idx, data in enumerate(train_dataloader):\n",
    "            if idx==0:\n",
    "                print(\"batch size : \", len(data[0]['input_ids']))\n",
    "                print(\"The first batch looks like ..\\n\", data[0])\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_steps = len(train_dataloader) * args.train_epochs\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * args.warmup_proportion), num_training_steps=total_steps)\n",
    "\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.to(DEVICE)\n",
    "        criterion = criterion.to(DEVICE)\n",
    "        \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0\n",
    "    best_score = 0\n",
    "      \n",
    "\n",
    "    for epoch_num in range(args.train_epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "            \n",
    "            assert mode in ['train', 'val'], 'your mode should be either \\'train\\' or \\'val\\''\n",
    "            \n",
    "            if mode =='train':\n",
    "                for train_input, train_label in tqdm(train_dataloader):\n",
    "                    \n",
    "                    mask = train_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = train_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = train_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    train_label = train_label.long().to(DEVICE)                \n",
    "\n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "                    \n",
    "                    batch_loss = criterion(output.view(-1,6), train_label.view(-1))\n",
    "                    total_loss_train += batch_loss.item()\n",
    "\n",
    "                    acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                    total_acc_train += acc\n",
    "\n",
    "                    model.zero_grad()\n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            # validation을 위해 이걸 넣으면 이 evaluation 프로세스 중엔 dropout 레이어가 다르가 동작한다.\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    mask = val_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = val_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    val_label = val_label.long().to(DEVICE)\n",
    "\n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "\n",
    "                    batch_loss = criterion(output.view(-1,6), val_label.view(-1))\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            \n",
    "            train_loss = total_loss_train / len(train_data)\n",
    "            train_accuracy = total_acc_train / len(train_data)\n",
    "            val_loss = total_loss_val / len(val_data)\n",
    "            val_accuracy = total_acc_val / len(val_data)\n",
    "            \n",
    "            # 한 Epoch 학습 후 학습/검증에 대해 loss와 평가지표 (여기서는 accuracy로 임의로 설정) 출력\n",
    "            print(\n",
    "                f'Epoch: {epoch_num + 1} \\\n",
    "                | Train Loss: {train_loss: .3f} \\\n",
    "                | Train Accuracy: {train_accuracy: .3f} \\\n",
    "                | Val Loss: {val_loss: .3f} \\\n",
    "                | Val Accuracy: {val_accuracy: .3f}')\n",
    "          \n",
    "            # early_stopping check\n",
    "            early_stopper.check_early_stopping(loss=val_loss)\n",
    "\n",
    "            if early_stopper.stop:\n",
    "                print('Early stopped, Best score : ', best_score)\n",
    "                break\n",
    "\n",
    "            if val_accuracy > best_score:\n",
    "            # 모델이 개선됨 -> 검증 점수와 weight 갱신\n",
    "                best_score = val_accuracy\n",
    "                \n",
    "                # 학습된 모델을 저장할 디렉토리 및 모델 이름 지정\n",
    "                SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "            \n",
    "                check_point = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict()\n",
    "                }\n",
    "                torch.save(check_point, SAVED_MODEL)  \n",
    "              \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "train(model, train_dataset, val_dataset, args, mode = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301514c-7d9e-4f37-9e8c-db85e3819b8b",
   "metadata": {},
   "source": [
    "## 6. Test dataset으로 추론 (Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32696c34-b5e6-43b3-a1e7-ed8c2847baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 테스트 데이터셋 불러오기\n",
    "test_data = CustomDataset(test_df, tokenizer = TOKENIZER, max_len= args.max_seq_len, mode='test')\n",
    "\n",
    "def test(model, SAVED_MODEL, test_data, args, mode = 'test'):\n",
    "\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=args.eval_batch_size)\n",
    "\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.to(DEVICE)\n",
    "        model.load_state_dict(torch.load(SAVED_MODEL)['model'])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input in test_dataloader:\n",
    "\n",
    "            mask = test_input['attention_mask'].to(DEVICE)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "            segment_ids = test_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "\n",
    "            output = model(input_id, mask, segment_ids)\n",
    "\n",
    "            output = output.argmax(dim=1).cpu().tolist()\n",
    "\n",
    "            for label in output:\n",
    "                pred.append(label)\n",
    "                \n",
    "    return pred\n",
    "\n",
    "SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "\n",
    "pred = test(model, SAVED_MODEL, test_data, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29432647-7a5d-4dda-99af-ad6f151fd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prediction completed for \", len(pred), \"comments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aaf8d-93c6-4998-b005-f32ec5986f46",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc3c34-e3a8-4172-8b16-f1c2a5bb5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-5 사이의 라벨 값 별로 bias, hate로 디코딩 하기 위한 딕셔너리\n",
    "bias_dict = {0: 'none', 1: 'none', 2: 'others', 3:'others', 4:'gender', 5:'gender'}\n",
    "hate_dict = {0: 'none', 1: 'hate', 2: 'none', 3:'hate', 4:'none', 5:'hate'}\n",
    "\n",
    "# 인코딩 값으로 나온 타겟 변수를 디코딩\n",
    "pred_bias = ['' for i in range(len(pred))]\n",
    "pred_hate = ['' for i in range(len(pred))]\n",
    "\n",
    "for idx, label in enumerate(pred):\n",
    "    pred_bias[idx]=(str(bias_dict[label]))\n",
    "    pred_hate[idx]=(str(hate_dict[label]))\n",
    "print('decode Completed!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6cdb3-8245-468e-aaf0-4e6f328e98c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(args.data_dir,'sample_submission.csv'))\n",
    "\n",
    "submit['bias'] = pred_bias\n",
    "submit['hate'] = pred_hate\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b5159-8ffe-4cc2-833b-3c4b0c857022",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(args.result_dir, f\"submission_{args.run}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a30767-7803-448a-950b-412b71088d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89023af-867b-4d28-b30d-e465d0abe66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
